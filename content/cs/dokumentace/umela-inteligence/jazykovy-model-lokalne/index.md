+++
date = '2025-03-25T09:59:04Z'
draft = false
title = 'Jak spustit vlastnÃ­ jazykovÃ½ model lokÃ¡lnÄ›: KompletnÃ­ nÃ¡vod'
kategorie = ['NÃ¡vod']
tags = ['LLM', 'Ollama', 'Docker', 'OpenWebUI', 'AI']
ShowToc = true
TocOpen = true

+++

## ProÄ provozovat jazykovÃ½ model lokÃ¡lnÄ›?

LokÃ¡lnÃ­ AI vÃ¡m dÃ¡vÃ¡ kontrolu nad daty, pracuje offline, umoÅ¾Åˆuje hlubÅ¡Ã­ integrace do vlastnÃ­ch aplikacÃ­ a dlouhodobÄ› Å¡etÅ™Ã­ nÃ¡klady.

> ğŸ“¦Â **Open-source projekt:**Â Tento nÃ¡vod vychÃ¡zÃ­ z open-source stacku dostupnÃ©ho na GitHubu:Â [ZiMi-lab/local-llm-stack](https://github.com/ZiMi-lab/local-llm-stack), kde najdete veÅ¡kerÃ© konfiguraÄnÃ­ soubory, Å¡ablony a dalÅ¡Ã­ nÃ¡stroje potÅ™ebnÃ© k nasazenÃ­ lokÃ¡lnÃ­ho jazykovÃ©ho modelu.

![UkÃ¡zka z Open WebUI](jazykovy-model-lokalne.gif)

---

## PoÅ¾adavky na instalaci

**HardwarovÃ© poÅ¾adavky:**
- NVIDIA GPU s podporou CUDA
- Min. 16 GB RAM (doporuÄeno vÃ­ce pro vÄ›tÅ¡Ã­ modely)
- SSD disk

**Software:**
- Linux nebo WSL2/macOS (s omezenÃ­m GPU podpory)
- [Docker + Docker Compose](https://docs.docker.com/engine/install/)
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)
- [Ollama (mimo Docker)](https://github.com/ollama/ollama/blob/main/docs/linux.md)

---

## Instalace krok za krokem

### 1. Instalace Dockeru a NVIDIA nÃ¡strojÅ¯

```bash
apt-get update
apt-get install ca-certificates curl
install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo tee /etc/apt/keyrings/docker.asc > /dev/null
chmod a+r /etc/apt/keyrings/docker.asc
echo \  
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \  
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \  
  tee /etc/apt/sources.list.d/docker.list > /dev/null
apt-get update
apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin
```

### 2. Instalace Ollamy

```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama help  # ovÄ›Å™enÃ­ funkÄnosti
```

VolitelnÄ› nastavte prostÅ™edÃ­ v systemd (v pÅ™Ã­padÄ›, kdy chcete povolit pÅ™Ã­stup k Ollama a jazykovÃ©mu modelu i z jinÃ½ch zaÅ™Ã­zenÃ­):
```bash
systemctl edit ollama.service
# pÅ™idejte:
[Service]
Environment="OLLAMA_HOST=0.0.0.0"

systemctl daemon-reload
systemctl restart ollama
```

---

### 3. KlonovÃ¡nÃ­ projektu a nastavenÃ­ prostÅ™edÃ­

```bash
git clone https://github.com/ZiMi-lab/local-llm-stack.git
cd local-llm-stack
cp .env.example .env
nano .env  # upravte napÅ™. WEBUI_URL, OLLAMA_BASE_URL
```

> ğŸ›¡ï¸ **BezpeÄnostnÃ­ poznÃ¡mka:** Soubor `.env` obsahuje citlivÃ© Ãºdaje jako URL, API klÃ­Äe Äi konfiguraÄnÃ­ volby. Tento soubor by mÄ›l bÃ½t vÅ¾dy uveden v `.gitignore` a **nikdy necommitovÃ¡n do veÅ™ejnÃ©ho repozitÃ¡Å™e**. Pokud provozujete systÃ©m ve veÅ™ejnÃ© sÃ­ti, ujistÄ›te se, Å¾e soubor je chrÃ¡nÄ›n sprÃ¡vnÃ½mi pÅ™Ã­stupovÃ½mi prÃ¡vy (`chmod 600 .env`).

ZkopÃ­rujte Nginx Å¡ablonu:
```bash
cp nginx/templates/default.conf.template.example nginx/templates/default.conf.template
```

---

### 4. NastavenÃ­ SSL certifikÃ¡tÅ¯

Do sloÅ¾ky `nginx/ssl` vloÅ¾te:
- `cert.crt` â€“ certifikÃ¡t
- `privkey.key` â€“ privÃ¡tnÃ­ klÃ­Ä

Pro testovÃ¡nÃ­ lze vygenerovat self-signed certifikÃ¡t:
```bash
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
-keyout nginx/ssl/privkey.key \
-out nginx/ssl/cert.crt
```

---

### 5. SpuÅ¡tÄ›nÃ­ sluÅ¾eb

```bash
docker compose up -d
```

OvÄ›Å™enÃ­ bÄ›hu:
```bash
docker ps
```

WebovÃ© rozhranÃ­ by mÄ›lo bÃ½t dostupnÃ© na:
- http://localhost:3000 (nebo pÅ™es reverznÃ­ proxy na vlastnÃ­ domÃ©nÄ›)

---

## Popis sluÅ¾eb

Docker Compose nasazuje:
- **openwebui** â€“ webovÃ© rozhranÃ­ pro LLM (Open WebUI)
- **nginx** â€“ reverznÃ­ proxy (moÅ¾nost SSL)
- **watchtower** â€“ automatickÃ¡ aktualizace kontejnerÅ¯
- **tika** â€“ extrakce textu z dokumentÅ¯ (PDF, DOC)
- **backend** â€“ API a zpracovÃ¡nÃ­ souborÅ¯

> â„¹ï¸ **PoznÃ¡mka k aktualizacÃ­m:** AutomatickÃ© aktualizace pomocÃ­ sluÅ¾by `watchtower` usnadÅˆujÃ­ ÃºdrÅ¾bu, ale **v produkÄnÃ­m prostÅ™edÃ­ se doporuÄuje ruÄnÃ­ kontrola a testovÃ¡nÃ­ aktualizacÃ­**, aby nedoÅ¡lo k neÄekanÃ©mu vÃ½padku sluÅ¾eb.

---
## NahrÃ¡vÃ¡nÃ­ dokumentÅ¯ pÅ™es API

FastAPI backend nabÃ­zÃ­ endpoint `/upload`:

**PÅ™Ã­klad cURL (Linux):**
```bash
curl -X POST https://vÃ¡Å¡server.cz/upload \
-F "token=secret123" \
-F "target_dir=docs" \
-F "files=@file.pdf"
```

---

## Aktualizace a ÃºdrÅ¾ba

Pro aktualizaci staÄÃ­:
```bash
cd /opt/webui
docker compose pull
docker compose up --force-recreate --build -d
docker image prune -f
```

---

## ShrnutÃ­

S vyuÅ¾itÃ­m nÃ¡strojÅ¯ jako Docker, Ollama a Open WebUI lze spustit jazykovÃ½ model lokÃ¡lnÄ›, vÄetnÄ› webovÃ©ho rozhranÃ­, zpracovÃ¡nÃ­ dokumentÅ¯ a moÅ¾nosti RAG databÃ¡ze. Tento pÅ™Ã­stup pÅ™inÃ¡Å¡Ã­ kontrolu nad daty, offline dostupnost a flexibilitu pro pokroÄilÃ© integrace.